{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Суперсеть с Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pylab as plt\n",
    "from torch.nn.utils import clip_grad_value_\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 32*32*1 \n",
    "class_num = 10\n",
    "n_epochs =  20\n",
    "fine_tune_epochs = 10\n",
    "batch_size = 256\n",
    "random_seed = 42\n",
    "valid_size = 0.1 # валидация не используется. Сохраняем ее для чистоты эксперимента\n",
    "trials = 10\n",
    "search_space = [1, 16, 32, 64, 256, 512, 1024]  # '1' кодирует тождественное отображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.CIFAR10('./files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                  torchvision.transforms.Lambda(lambda x: x.mean(0).view(-1))\n",
    "                             ]))\n",
    "\n",
    "test_data = torchvision.datasets.CIFAR10('./files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                              (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                  torchvision.transforms.Lambda(lambda x: x.mean(0).view(-1))\n",
    "                             ]))\n",
    "\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = t.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=0, pin_memory=True )\n",
    "test_loader = t.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "valid_loader = t.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedLayer(nn.Module):\n",
    "    def __init__(self, in_, dims, act=F.tanh):\n",
    "        nn.Module.__init__(self)            \n",
    "        self.dims = dims\n",
    "        self.layer = nn.Linear(in_, max(dims)).cuda() \n",
    "        self.act =  act        \n",
    "        self.s = nn.Parameter(t.ones(len(dims), device='cuda')+ t.randn(len(dims), device='cuda')*.0)    \n",
    "        # мы добавляем шум в слои для уменьшения возможной подстройки одного слоя под другой\n",
    "        # в противном случае становится более вероятным случай, когда\n",
    "        # в первую очередь выбирается наиболее простая подмодель, а остальные \"достраиваются\"\n",
    "        # с небольшими значениями для структурных параметров\n",
    "        self.noises = [t.randn(in_).cuda() for _ in range(len(dims))]\n",
    "        \n",
    "    def forward(self, x, temp):\n",
    "        gamma = F.softmax(self.s/temp)\n",
    "        var_result = self.act(self.layer(x))\n",
    "        \n",
    "        result = t.zeros(x.shape).cuda()\n",
    "        for i,d in enumerate(self.dims):\n",
    "            if d == 1:\n",
    "                result = result + (x + self.noises[i])*gamma[i] \n",
    "            else:\n",
    "                result[:,:d] =result[:,:d] +  (var_result[:,:d]+self.noises[i][:d])*gamma[i]            \n",
    "        return result\n",
    "  \n",
    "        \n",
    "    \n",
    "class SuperNet(nn.Module):\n",
    "    def __init__(self, dims,  layer_num):\n",
    "        nn.Module.__init__(self)\n",
    "        layers = []\n",
    "        for l in range(layer_num):\n",
    "            layers.append(MixedLayer(input_dim, dims )) \n",
    "        layers.append(nn.Linear(input_dim, 10).cuda()) \n",
    "            \n",
    "      \n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x, temp):\n",
    "        for l in self.model:\n",
    "            if isinstance(l, MixedLayer):\n",
    "            \n",
    "                x = l(x, temp)\n",
    "            else:\n",
    "                x = l(x)\n",
    "        return x\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc(model, loader, temp, func = lambda x:x):\n",
    "    tp = 0\n",
    "    cases = 0\n",
    "    model.eval()\n",
    "    for x,y in loader: \n",
    "            x = func(x)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            if temp is None:\n",
    "                out = model(x).argmax(1)\n",
    "            else:\n",
    "                out = model(x, temp).argmax(1)\n",
    "            tp+=(out==y).sum()\n",
    "            cases+=len(y)\n",
    "    model.train()\n",
    "    return  tp.cpu().numpy()*1.0/cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "t.manual_seed(random_seed)\n",
    "id=0\n",
    "for trial in range(trials):\n",
    "    net = SuperNet(search_space, 4)\n",
    "    struct = [m.s for m in net.model if isinstance(m, MixedLayer)]\n",
    "    optimizer1 = optim.Adam([p for p in net.parameters() if p not in set(struct)], lr=0.001)\n",
    "    optimizer2 = optim.Adam(struct, lr=0.01) \n",
    "    loss_fn = nn.CrossEntropyLoss()    \n",
    "    for epoch in range(n_epochs):        \n",
    "        for x,y in train_loader:\n",
    "            id+=1\n",
    "\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()            \n",
    "            optimizer1.zero_grad()\n",
    "            optimizer2.zero_grad()\n",
    "            loss = 0\n",
    "            out_loss = 0\n",
    "            out = net(x, 1.0)\n",
    "            out_loss += loss_fn(out, y)*len(train_idx)*1.0        \n",
    "            loss = (out_loss)       \n",
    "            if id %100 == 0:\n",
    "                print (net.model[0].s)\n",
    "                print (out_loss.data)\n",
    "                print ('\\n')\n",
    "\n",
    "            loss.backward()\n",
    "            clip_grad_value_(net.parameters(), 1.0)            \n",
    "            optimizer1.step()  \n",
    "            optimizer2.step()   \n",
    "\n",
    "        acc = test_acc(net, valid_loader, 0.2)            \n",
    "        print ('Trial {0}. Epoch {1}. Acc: {2}'.format(trial, epoch, acc))\n",
    "    with open( 'naive_supernet{0}.pckl'.format(trial), 'wb') as out:\n",
    "        pickle.dump(net, out)\n",
    "    del net\n",
    "    t.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer(nn.Module):\n",
    "    def __init__(self, bias):\n",
    "        nn.Module.__init__(self)\n",
    "        self.bias = bias\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.bias\n",
    "    \n",
    "def supernet_structure_to_net(model):\n",
    "    var_layers = []\n",
    "    in_dim = input_dim\n",
    "    for mixed_layer in model.model[:-1]:        \n",
    "        if isinstance(mixed_layer, MixedLayer):\n",
    "            best_layer_id = mixed_layer.s.argmax()\n",
    "            if mixed_layer.dims[best_layer_id] == 1:\n",
    "                continue\n",
    "            print (best_layer_id)\n",
    "            new_layer = nn.Linear(in_dim, mixed_layer.dims[best_layer_id]).cuda()\n",
    "            new_layer.weight.data *= 0\n",
    "            new_layer.weight.data += mixed_layer.layer.weight[:mixed_layer.dims[best_layer_id], :in_dim]\n",
    "            new_layer.bias.data *= 0\n",
    "            new_layer.bias.data += mixed_layer.layer.bias[:mixed_layer.dims[best_layer_id]]\n",
    "            var_layers.append(new_layer)\n",
    "            var_layers.append(nn.Tanh())\n",
    "            var_layers.append(AddLayer(mixed_layer.noises[best_layer_id][:mixed_layer.dims[best_layer_id]]))\n",
    "            \n",
    "            in_dim = mixed_layer.dims[best_layer_id]\n",
    "    \n",
    "    sublayer = model.model[-1] \n",
    "    out_ = 10\n",
    "    \n",
    "    new_layer = nn.Linear(in_dim, out_).cuda()\n",
    "    new_layer.weight.data *= 0\n",
    "    new_layer.weight.data += sublayer.weight[:, :in_dim]\n",
    "    new_layer.bias.data *= 0\n",
    "    new_layer.bias.data += sublayer.bias[:in_dim]\n",
    "            \n",
    "    var_layers.append(new_layer)\n",
    "    return nn.Sequential(*var_layers)\n",
    "#subnet = supernet_structure_to_net(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дообучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "tuned_nets = []\n",
    "for trial in range(trials):\n",
    "    with open( 'naive_supernet{0}.pckl'.format(trial), 'rb') as inp:\n",
    "        net = pickle.load(inp)\n",
    "    subnet = supernet_structure_to_net(net)\n",
    "    optimizer1 = optim.Adam(subnet.parameters(), lr=0.001) # для параметров\n",
    "    loss_fn = nn.CrossEntropyLoss()    \n",
    "    id=0\n",
    "    for epoch in range(fine_tune_epochs):        \n",
    "        for x,y in train_loader:\n",
    "            id+=1\n",
    "\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()            \n",
    "            optimizer1.zero_grad()        \n",
    "            loss = 0\n",
    "            out_loss = 0\n",
    "            out = subnet(x)\n",
    "            out_loss += loss_fn(out, y)*len(train_idx)*1.0        \n",
    "            loss = (out_loss)       \n",
    "            if id %100 == 0:            \n",
    "                print (out_loss.data)\n",
    "                print ('\\n')\n",
    "\n",
    "            loss.backward()\n",
    "            clip_grad_value_(net.parameters(), 1.0)            \n",
    "            optimizer1.step()  \n",
    "\n",
    "        acc = test_acc(subnet, valid_loader, None)            \n",
    "        print ('Trial {0}. Epoch {1}. Acc: {2}'.format(trial, epoch, acc))\n",
    "    tuned_nets.append(subnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./naive_supernet_tuned.pckl', 'wb') as out:\n",
    "    pickle.dump(tuned_nets, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = []\n",
    "for subnet in tuned_nets:    \n",
    "    num = 0\n",
    "    for p in subnet.parameters():\n",
    "    \n",
    "        if len(p.size())==1:\n",
    "            num+=p.size()[0]\n",
    "        elif len(p.size())==0:\n",
    "            num+=1\n",
    "        else:\n",
    "            num+=p.size()[1]*p.size()[0]\n",
    "    pn.append(num)\n",
    "\n",
    "stats['param number'] = pn\n",
    "stats['param number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_superposition_number(): \n",
    "    sn = []\n",
    "    for subnet in tuned_nets:\n",
    "        cnt = 0\n",
    "        for submodel in subnet:\n",
    "            if len(list(submodel.parameters()))>0:\n",
    "                cnt+=1\n",
    "        sn.append(cnt)\n",
    "        \n",
    "    return sn\n",
    "stats['superposition number'] = get_superposition_number()\n",
    "stats['superposition number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.manual_seed(random_seed)\n",
    "X = []\n",
    "Y = []\n",
    "Y_std = []\n",
    "accs = []\n",
    "for noise in np.linspace(0, 1.0, 10):\n",
    "    X.append(noise)\n",
    "    acc = []\n",
    "    for subnet in tuned_nets:\n",
    "                     \n",
    "        acc += [test_acc(subnet, test_loader, None, func = lambda x: x+t.randn(x.size())*noise)] \n",
    "    print (acc)\n",
    "    Y.append(np.mean(acc))\n",
    "    Y_std.append(np.std(acc))\n",
    "    accs.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats['noise'] = [X,Y,Y_std, accs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.manual_seed(random_seed)\n",
    "X = []\n",
    "Y = []\n",
    "Y_std = []\n",
    "accs = []\n",
    "for noise in range(1, 10):\n",
    "    noise = int(noise)\n",
    "    def blur(x):\n",
    "        \n",
    "        kernel = t.ones(1,1,noise, noise)*1.0/noise/noise\n",
    "        \n",
    "        x_ = x.view(-1, 1, 32, 32)\n",
    "        \n",
    "        x_ = F.conv2d(x_,  kernel, stride=1)    \n",
    "        \n",
    "        x_ = F.upsample(x_, ( 32,32)).view(-1, 32*32)\n",
    "        return x_\n",
    "    \n",
    "    X.append(noise)\n",
    "    acc = []\n",
    "    for subnet in tuned_nets:\n",
    "                     \n",
    "        acc += [test_acc(subnet, test_loader, None, func = blur)] \n",
    "    print (acc)\n",
    "    Y.append(np.mean(acc))\n",
    "    Y_std.append(np.std(acc))\n",
    "    accs.append(acc)\n",
    "stats['blur'] = [X,Y,Y_std, accs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.manual_seed(random_seed)\n",
    "X = []\n",
    "Y = []\n",
    "accs = []\n",
    "Y_std = []\n",
    "for noise in np.linspace(0, 0.1, 10):\n",
    "    X.append(noise)\n",
    "    acc = []\n",
    "    for subnet in tuned_nets:\n",
    "        m = subnet\n",
    "\n",
    "        old_params = []\n",
    "        for p in m.parameters():\n",
    "            old_params.append(p.data*1.0)\n",
    "\n",
    "        tp = 0        \n",
    "        for x,y in test_loader:\n",
    "\n",
    "            for p, o in zip(m.parameters(), old_params):                \n",
    "                n = t.randn(p.data.shape)*noise\n",
    "                n = n.cuda()                    \n",
    "                p.data = o + n\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            out = m(x).argmax(1)\n",
    "            tp+=(out==y).sum()\n",
    "            for p, o in zip(m.parameters(), old_params):                \n",
    "                p.data = o\n",
    "        acc.append(tp.cpu().numpy()*1.0/len(test_data))\n",
    "    print (acc)\n",
    "    accs.append(acc)\n",
    "    Y.append(np.mean(acc))\n",
    "    Y_std.append(np.std(acc))\n",
    "stats['params'] = [X,Y,Y_std, accs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./naive_supernet_stats.pckl', 'wb') as out:\n",
    "    pickle.dump(stats, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
